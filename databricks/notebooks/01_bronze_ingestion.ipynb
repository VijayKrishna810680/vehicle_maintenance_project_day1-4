{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f23deec",
   "metadata": {},
   "source": [
    "# Bronze Layer Data Ingestion\n",
    "## Raw Data Ingestion to Delta Lake\n",
    "\n",
    "This notebook implements the Bronze layer of our medallion architecture:\n",
    "1. Read data from source systems (JSON files, APIs, databases)\n",
    "2. Minimal transformations (parsing, type conversion)\n",
    "3. Store raw data in Delta format with metadata\n",
    "4. Track data lineage and ingestion timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cec0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import *\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"VehicleMaintenance-Bronze\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set database\n",
    "spark.sql(\"USE vehicle_maintenance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d17e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for raw maintenance records\n",
    "maintenance_schema = StructType([\n",
    "    StructField(\"vehicle_id\", StringType(), True),\n",
    "    StructField(\"maintenance_date\", TimestampType(), True),\n",
    "    StructField(\"service_type\", StringType(), True),\n",
    "    StructField(\"mileage\", LongType(), True),\n",
    "    StructField(\"cost\", DoubleType(), True),\n",
    "    StructField(\"technician\", StringType(), True),\n",
    "    StructField(\"notes\", StringType(), True),\n",
    "    StructField(\"parts_used\", ArrayType(StringType()), True)\n",
    "])\n",
    "\n",
    "# Function to ingest raw data from JSON files\n",
    "def ingest_maintenance_records(source_path):\n",
    "    # Read JSON files\n",
    "    raw_df = spark.read.schema(maintenance_schema).json(source_path)\n",
    "    \n",
    "    # Add metadata columns\n",
    "    enriched_df = raw_df.withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "    \n",
    "    # Write to bronze Delta table\n",
    "    enriched_df.write.format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .saveAsTable(\"vehicle_maintenance.bronze_maintenance\")\n",
    "    \n",
    "    return enriched_df\n",
    "\n",
    "# Example ingestion (replace with your source path)\n",
    "source_path = \"/mnt/vehicle-data/raw/maintenance/*.json\"\n",
    "try:\n",
    "    df = ingest_maintenance_records(source_path)\n",
    "    print(f\"Ingested {df.count()} records to bronze layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f850999",
   "metadata": {},
   "source": [
    "## Data Quality Checks\n",
    "\n",
    "Implement basic data quality checks on ingested data:\n",
    "1. Schema validation\n",
    "2. Null checks for required fields\n",
    "3. Data type validation\n",
    "4. Record count monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform data quality checks\n",
    "def check_data_quality(df):\n",
    "    total_records = df.count()\n",
    "    \n",
    "    # Check for nulls in required fields\n",
    "    null_checks = df.select([\n",
    "        count(when(col(c).isNull(), c)).alias(f\"{c}_nulls\")\n",
    "        for c in [\"vehicle_id\", \"maintenance_date\", \"service_type\", \"mileage\"]\n",
    "    ])\n",
    "    \n",
    "    # Check for invalid dates (future dates)\n",
    "    future_dates = df.filter(col(\"maintenance_date\") > current_timestamp()).count()\n",
    "    \n",
    "    # Check for negative values\n",
    "    invalid_mileage = df.filter(col(\"mileage\") < 0).count()\n",
    "    invalid_cost = df.filter(col(\"cost\") < 0).count()\n",
    "    \n",
    "    print(\"Data Quality Report:\")\n",
    "    print(f\"Total Records: {total_records}\")\n",
    "    null_checks.show()\n",
    "    print(f\"Future Dates: {future_dates}\")\n",
    "    print(f\"Invalid Mileage Records: {invalid_mileage}\")\n",
    "    print(f\"Invalid Cost Records: {invalid_cost}\")\n",
    "    \n",
    "    return total_records\n",
    "\n",
    "# Run quality checks on ingested data\n",
    "total_records = check_data_quality(df)\n",
    "print(f\"\\nData quality checks completed for {total_records} records\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
