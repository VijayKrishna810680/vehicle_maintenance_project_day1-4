{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba13d6a5",
   "metadata": {},
   "source": [
    "# Vehicle Maintenance Pipeline Integration Tests\n",
    "\n",
    "This notebook contains end-to-end tests for the vehicle maintenance data pipeline:\n",
    "1. Test Data Generation\n",
    "2. Bronze Layer Validation\n",
    "3. Silver Layer Transformation Tests\n",
    "4. Gold Layer Analytics Validation\n",
    "5. Data Quality Checks\n",
    "6. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5301628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import *\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import pytest\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"VehicleMaintenance-Tests\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set database\n",
    "spark.sql(\"USE vehicle_maintenance\")\n",
    "\n",
    "def test_setup():\n",
    "    \"\"\"Verify environment setup and connectivity\"\"\"\n",
    "    try:\n",
    "        # Check Delta Lake setup\n",
    "        tables = spark.sql(\"SHOW TABLES\").collect()\n",
    "        assert len(tables) > 0, \"No tables found in database\"\n",
    "        \n",
    "        # Check GCS mount\n",
    "        mount_point = \"/mnt/vehicle-data\"\n",
    "        assert any(mount_point in mount.mountPoint for mount in dbutils.fs.mounts()), \\\n",
    "            \"GCS mount point not found\"\n",
    "            \n",
    "        print(\"✓ Environment setup verified\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Setup verification failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Run setup test\n",
    "setup_ok = test_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7267dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "def generate_test_data(num_records=100):\n",
    "    \"\"\"Generate synthetic maintenance records for testing\"\"\"\n",
    "    \n",
    "    vehicles = [f\"VIN{i:03d}\" for i in range(10)]\n",
    "    service_types = [\n",
    "        \"Oil Change\", \"Brake Repair\", \"Tire Rotation\",\n",
    "        \"Engine Tune-up\", \"Filter Replacement\", \"Inspection\"\n",
    "    ]\n",
    "    technicians = [\"John\", \"Alice\", \"Bob\", \"Carol\", \"David\"]\n",
    "    parts = [\n",
    "        [\"Oil Filter\", \"Engine Oil\"],\n",
    "        [\"Brake Pads\", \"Brake Fluid\"],\n",
    "        [\"Air Filter\"],\n",
    "        [\"Spark Plugs\", \"Ignition Coil\"],\n",
    "        [\"Fuel Filter\", \"Air Filter\"],\n",
    "        []\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    base_date = datetime.now() - timedelta(days=365)\n",
    "    \n",
    "    for _ in range(num_records):\n",
    "        vehicle = random.choice(vehicles)\n",
    "        service_idx = random.randint(0, len(service_types)-1)\n",
    "        date = base_date + timedelta(days=random.randint(0, 365))\n",
    "        \n",
    "        record = {\n",
    "            \"vehicle_id\": vehicle,\n",
    "            \"maintenance_date\": date.isoformat(),\n",
    "            \"service_type\": service_types[service_idx],\n",
    "            \"mileage\": random.randint(5000, 100000),\n",
    "            \"cost\": round(random.uniform(50, 1000), 2),\n",
    "            \"technician\": random.choice(technicians),\n",
    "            \"notes\": f\"Regular {service_types[service_idx]}\",\n",
    "            \"parts_used\": parts[service_idx]\n",
    "        }\n",
    "        data.append(record)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    test_df = spark.createDataFrame(spark.sparkContext.parallelize(data))\n",
    "    return test_df\n",
    "\n",
    "def test_bronze_ingestion(test_df):\n",
    "    \"\"\"Test Bronze layer ingestion and validation\"\"\"\n",
    "    try:\n",
    "        # Write test data to bronze\n",
    "        test_df.write.format(\"delta\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .saveAsTable(\"vehicle_maintenance.test_bronze_maintenance\")\n",
    "        \n",
    "        # Verify data\n",
    "        bronze_df = spark.table(\"vehicle_maintenance.test_bronze_maintenance\")\n",
    "        assert bronze_df.count() >= len(test_df.collect()), \"Record count mismatch\"\n",
    "        \n",
    "        # Check schema\n",
    "        required_cols = [\"vehicle_id\", \"maintenance_date\", \"service_type\", \"mileage\"]\n",
    "        assert all(col in bronze_df.columns for col in required_cols), \"Missing required columns\"\n",
    "        \n",
    "        print(\"✓ Bronze layer tests passed\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Bronze layer test failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Generate and test bronze\n",
    "if setup_ok:\n",
    "    test_data = generate_test_data()\n",
    "    bronze_ok = test_bronze_ingestion(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Silver layer transformations\n",
    "def test_silver_transformations():\n",
    "    \"\"\"Test Silver layer data cleaning and enrichment\"\"\"\n",
    "    try:\n",
    "        # Read bronze test data\n",
    "        bronze_df = spark.table(\"vehicle_maintenance.test_bronze_maintenance\")\n",
    "        \n",
    "        # Apply silver transformations\n",
    "        silver_df = bronze_df \\\n",
    "            .withColumn(\"maintenance_date\", to_date(\"maintenance_date\")) \\\n",
    "            .withColumn(\"service_category\", \n",
    "                when(col(\"service_type\").isin([\"Oil Change\", \"Filter Replacement\"]), \"Routine\")\n",
    "                .when(col(\"service_type\").isin([\"Brake Repair\", \"Engine Tune-up\"]), \"Repair\")\n",
    "                .when(col(\"service_type\") == \"Inspection\", \"Inspection\")\n",
    "                .otherwise(\"Other\")) \\\n",
    "            .withColumn(\"labor_cost\", col(\"cost\") * 0.6) \\\n",
    "            .withColumn(\"parts_cost\", col(\"cost\") * 0.4) \\\n",
    "            .withColumn(\"maintenance_status\",\n",
    "                when(current_date() > add_months(col(\"maintenance_date\"), 6), \"Due\")\n",
    "                .otherwise(\"Current\")) \\\n",
    "            .withColumn(\"next_maintenance_date\", add_months(col(\"maintenance_date\"), 6))\n",
    "        \n",
    "        # Write to test silver table\n",
    "        silver_df.write.format(\"delta\") \\\n",
    "            .mode(\"append\") \\\n",
    "            .saveAsTable(\"vehicle_maintenance.test_silver_maintenance\")\n",
    "        \n",
    "        # Verify transformations\n",
    "        assert \"service_category\" in silver_df.columns, \"Missing service categorization\"\n",
    "        assert \"labor_cost\" in silver_df.columns, \"Missing cost breakdown\"\n",
    "        assert silver_df.filter(col(\"service_category\").isNull()).count() == 0, \\\n",
    "            \"Found uncategorized services\"\n",
    "        \n",
    "        print(\"✓ Silver layer tests passed\")\n",
    "        return True, silver_df\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Silver layer test failed: {str(e)}\")\n",
    "        return False, None\n",
    "\n",
    "# Run silver tests if bronze passed\n",
    "if 'bronze_ok' in locals() and bronze_ok:\n",
    "    silver_ok, silver_df = test_silver_transformations()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
