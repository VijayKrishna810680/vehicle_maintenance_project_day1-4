{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad35617",
   "metadata": {},
   "source": [
    "# Vehicle Maintenance Data Pipeline Setup\n",
    "## Environment Configuration and Storage Setup\n",
    "\n",
    "This notebook handles the initial setup for our data pipeline:\n",
    "1. Configure cloud storage mounting (GCS)\n",
    "2. Set up Databricks secrets and authentication\n",
    "3. Create Delta Lake database structure\n",
    "4. Install required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8f1fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from delta.tables import *\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize Spark session with Delta Lake support\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"VehicleMaintenanceETL\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:1.0.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7ff69e",
   "metadata": {},
   "source": [
    "## Cloud Storage Configuration\n",
    "\n",
    "Configure GCS storage mounting using service account credentials. Make sure you have:\n",
    "1. Created a GCS bucket for the project\n",
    "2. Set up service account with appropriate permissions\n",
    "3. Downloaded service account key JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f30e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCS configuration\n",
    "storage_bucket = \"vehicle-maintenance-data\"  # Replace with your bucket name\n",
    "mount_point = \"/mnt/vehicle-data\"\n",
    "\n",
    "# Configure GCS using service account\n",
    "service_account = dbutils.secrets.get(scope=\"vehicle-maintenance\", key=\"gcs-service-account\")\n",
    "spark.conf.set(\"google.cloud.auth.service.account.json.keyfile\", service_account)\n",
    "\n",
    "# Mount GCS bucket\n",
    "try:\n",
    "    dbutils.fs.mount(\n",
    "        source=f\"gs://{storage_bucket}\",\n",
    "        mount_point=mount_point,\n",
    "        extra_configs={\n",
    "            \"google.cloud.auth.service.account.enable\": \"true\",\n",
    "            \"fs.gs.impl\": \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\"\n",
    "        }\n",
    "    )\n",
    "    print(f\"Successfully mounted {storage_bucket} to {mount_point}\")\n",
    "except Exception as e:\n",
    "    if \"already mounted\" in str(e):\n",
    "        print(f\"Bucket {storage_bucket} already mounted to {mount_point}\")\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6d5d3",
   "metadata": {},
   "source": [
    "## Create Delta Lake Database Structure\n",
    "\n",
    "Initialize the database and create the folder structure for our medallion architecture:\n",
    "- Bronze: Raw data ingestion\n",
    "- Silver: Cleaned and validated data\n",
    "- Gold: Business-ready aggregated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5416e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database if not exists\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS vehicle_maintenance\")\n",
    "spark.sql(\"USE vehicle_maintenance\")\n",
    "\n",
    "# Create delta table locations\n",
    "delta_base_path = f\"{mount_point}/delta\"\n",
    "bronze_path = f\"{delta_base_path}/bronze\"\n",
    "silver_path = f\"{delta_base_path}/silver\"\n",
    "gold_path = f\"{delta_base_path}/gold\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for path in [bronze_path, silver_path, gold_path]:\n",
    "    dbutils.fs.mkdirs(path)\n",
    "    print(f\"Created directory: {path}\")\n",
    "\n",
    "# Create example bronze table schema\n",
    "vehicle_maintenance_schema = \"\"\"\n",
    "    vehicle_id STRING,\n",
    "    maintenance_date TIMESTAMP,\n",
    "    service_type STRING,\n",
    "    mileage LONG,\n",
    "    cost DOUBLE,\n",
    "    technician STRING,\n",
    "    notes STRING,\n",
    "    parts_used ARRAY<STRING>,\n",
    "    ingestion_timestamp TIMESTAMP\n",
    "\"\"\"\n",
    "\n",
    "# Create bronze table\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS vehicle_maintenance.bronze_maintenance (\n",
    "    {vehicle_maintenance_schema}\n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '{bronze_path}/maintenance'\n",
    "\"\"\")\n",
    "\n",
    "print(\"Database and table structure created successfully\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
